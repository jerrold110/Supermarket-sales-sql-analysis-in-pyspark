{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "The purpose of this project is to analyse supermarket sales data through asking Key business questions such as \n",
    "'What product categories are performing well and not well at generating profits?' and 'Which of our branches are not performing well in Total sales and customer satisfaction?', then writing SQL queries to retrieve the data that answers those questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset metadata \n",
    "\n",
    "Attribute descriptions\n",
    "\n",
    "Invoice id: Computer generated sales slip invoice identification number\n",
    "\n",
    "Branch: Branch of supercenter (3 branches are available identified by A, B and C).\n",
    "\n",
    "City: Location of supercenters\n",
    "\n",
    "Customer type: Type of customers, recorded by Members for customers using member card and Normal for without member card.\n",
    "\n",
    "Gender: Gender type of customer\n",
    "\n",
    "Product line: General item categorization groups - Electronic accessories, Fashion accessories, Food and beverages, Health and beauty, Home and lifestyle, Sports and travel\n",
    "\n",
    "Unit price: Price of each product in $\n",
    "\n",
    "Quantity: Number of products purchased by customer\n",
    "\n",
    "Tax: 5% tax fee for customer buying\n",
    "\n",
    "Total: Total price including tax\n",
    "\n",
    "Date: Date of purchase (Record available from January 2019 to March 2019)\n",
    "\n",
    "Time: Purchase time (10am to 9pm)\n",
    "\n",
    "Payment: Payment used by customer for purchase (3 methods are available â€“ Cash, Credit card and Ewallet)\n",
    "\n",
    "COGS: Cost of goods sold\n",
    "\n",
    "Gross margin percentage: Gross margin percentage\n",
    "\n",
    "Gross income: Gross income\n",
    "\n",
    "Rating: Customer stratification rating on their overall shopping experience (On a scale of 1 to 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark.sql.functions import col, unix_timestamp, to_date, to_timestamp, to_str, concat_ws\n",
    "from pyspark.sql.types import DoubleType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = pyspark.sql.SparkSession.builder.appName(\"Sales queries\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://LAPTOP-R0JROKIO:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Sales queries</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x2e182a815b0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Records = 1000\n",
      "root\n",
      " |-- Invoice ID: string (nullable = true)\n",
      " |-- Branch: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Customer type: string (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Product line: string (nullable = true)\n",
      " |-- Unit price: string (nullable = true)\n",
      " |-- Quantity: string (nullable = true)\n",
      " |-- Tax 5%: string (nullable = true)\n",
      " |-- Total: string (nullable = true)\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Time: string (nullable = true)\n",
      " |-- Payment: string (nullable = true)\n",
      " |-- cogs: string (nullable = true)\n",
      " |-- gross margin percentage: string (nullable = true)\n",
      " |-- gross income: string (nullable = true)\n",
      " |-- Rating: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_raw = spark.read.csv('data/supermarket_sales.csv', header=True, sep=\",\").cache()\n",
    "print('Total Records = {}'.format(df_raw.count()))\n",
    "df_raw.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting to proper format\n",
    "* Date and time- convert to datetime and timestamp\n",
    "* Financial values - convert to double\n",
    "* Rating - convert to double"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unit price\n",
      "Quantity\n",
      "Tax 5%\n",
      "Total\n",
      "payment\n",
      "cogs\n",
      "gross margin percentage\n",
      "gross income\n",
      "rating\n",
      "root\n",
      " |-- Invoice ID: string (nullable = true)\n",
      " |-- Branch: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Customer type: string (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Product line: string (nullable = true)\n",
      " |-- Unit price: double (nullable = true)\n",
      " |-- Quantity: double (nullable = true)\n",
      " |-- Tax 5%: double (nullable = true)\n",
      " |-- Total: double (nullable = true)\n",
      " |-- Date: date (nullable = true)\n",
      " |-- Time: timestamp (nullable = true)\n",
      " |-- payment: double (nullable = true)\n",
      " |-- cogs: double (nullable = true)\n",
      " |-- gross margin percentage: double (nullable = true)\n",
      " |-- gross income: double (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      "\n",
      "+-----------+------+---------+-------------+------+--------------------+----------+--------+-------+--------+----------+-------------------+-------+------+-----------------------+------------+------+\n",
      "| Invoice ID|Branch|     City|Customer type|Gender|        Product line|Unit price|Quantity| Tax 5%|   Total|      Date|               Time|payment|  cogs|gross margin percentage|gross income|rating|\n",
      "+-----------+------+---------+-------------+------+--------------------+----------+--------+-------+--------+----------+-------------------+-------+------+-----------------------+------------+------+\n",
      "|750-67-8428|     A|   Yangon|       Member|Female|   Health and beauty|     74.69|     7.0|26.1415|548.9715|2019-01-05|2019-01-05 13:08:00|   null|522.83|            4.761904762|     26.1415|   9.1|\n",
      "|226-31-3081|     C|Naypyitaw|       Normal|Female|Electronic access...|     15.28|     5.0|   3.82|   80.22|2019-03-08|2019-03-08 10:29:00|   null|  76.4|            4.761904762|        3.82|   9.6|\n",
      "|631-41-3108|     A|   Yangon|       Normal|  Male|  Home and lifestyle|     46.33|     7.0|16.2155|340.5255|2019-03-03|2019-03-03 13:23:00|   null|324.31|            4.761904762|     16.2155|   7.4|\n",
      "|123-19-1176|     A|   Yangon|       Member|  Male|   Health and beauty|     58.22|     8.0| 23.288| 489.048|2019-01-27|2019-01-27 20:33:00|   null|465.76|            4.761904762|      23.288|   8.4|\n",
      "|373-73-7910|     A|   Yangon|       Normal|  Male|   Sports and travel|     86.31|     7.0|30.2085|634.3785|2019-02-08|2019-02-08 10:37:00|   null|604.17|            4.761904762|     30.2085|   5.3|\n",
      "+-----------+------+---------+-------------+------+--------------------+----------+--------+-------+--------+----------+-------------------+-------+------+-----------------------+------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert Time column to timestamp after concatenating it with date\n",
    "# or else the default system date of 1970-01-01 will be used for the day\n",
    "\n",
    "df = df_raw.withColumn('Time', concat_ws('_','Date','Time'))\n",
    "df = df.withColumn('Time', \n",
    "                  to_timestamp(unix_timestamp(col('Time'), 'M/d/yyyy_HH:mm').cast(\"timestamp\")))\n",
    "\n",
    "# Convert Date column to timestamp\n",
    "df = df.withColumn('Date', \n",
    "                  to_date(unix_timestamp(col('Date'), 'M/d/yyyy').cast(\"timestamp\")))\n",
    "\n",
    "# Financial values \n",
    "for col in ('Unit price', 'Quantity', 'Tax 5%', 'Total','payment','cogs','gross margin percentage', 'gross income', 'rating'):\n",
    "    print(col)\n",
    "    df = df.withColumn(col, df[col].cast(DoubleType()))\n",
    "\n",
    "df.printSchema()\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function for easy display of SQL query pyspark dataframes\n",
    "df.registerTempTable(\"sales\")\n",
    "\n",
    "def show_df(sqlquery):\n",
    "    spark.sql(sqlquery).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|first_date| last_date|\n",
      "+----------+----------+\n",
      "|2019-01-01|2019-03-30|\n",
      "+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_df('Select min(Date) as first_date,max(Date) as last_date from sales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+\n",
      "|Branch|     City|\n",
      "+------+---------+\n",
      "|     A|   Yangon|\n",
      "|     B| Mandalay|\n",
      "|     C|Naypyitaw|\n",
      "+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_df('Select Branch, City from sales group by Branch, City order by Branch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+----------+\n",
      "|Branch|Gender|Avg_rating|\n",
      "+------+------+----------+\n",
      "|     A|  Male|     7.196|\n",
      "|     A|Female|     6.839|\n",
      "|     B|  Male|     6.762|\n",
      "|     B|Female|     6.877|\n",
      "|     C|  Male|     6.972|\n",
      "|     C|Female|     7.158|\n",
      "+------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Average rating by Branch and gender\n",
    "show_df('Select Branch, Gender, Round(avg(Rating),3) as Avg_rating from sales group by Branch, Gender order by Branch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+\n",
      "|max_sale|min_sale|\n",
      "+--------+--------+\n",
      "| 1042.65| 10.6785|\n",
      "+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_df('Select max(Total) as max_sale, min(Total) as min_sale from sales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|        Product line|\n",
      "+--------------------+\n",
      "|  Home and lifestyle|\n",
      "| Fashion accessories|\n",
      "|   Health and beauty|\n",
      "|Electronic access...|\n",
      "|  Food and beverages|\n",
      "|   Sports and travel|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_df('Select distinct(`Product line`) from sales')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Queries by product line\n",
    "What product lines are under and over performing in terms of creating profit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----------+\n",
      "|        Product line|count|total_sales|\n",
      "+--------------------+-----+-----------+\n",
      "|  Home and lifestyle|  160|   53861.91|\n",
      "| Fashion accessories|  178|    54305.9|\n",
      "|   Health and beauty|  152|   49193.74|\n",
      "|Electronic access...|  170|   54337.53|\n",
      "|  Food and beverages|  174|   56144.84|\n",
      "|   Sports and travel|  166|   55122.83|\n",
      "+--------------------+-----+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sales per product line\n",
    "show_df(\"\"\"SELECT `Product line`,count(*) as count, round(sum(`total`), 2) as total_sales\n",
    "            FROM sales\n",
    "            GROUP BY `Product line`\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+------------+\n",
      "|        Product line|Avg_margin_percent|total_profit|\n",
      "+--------------------+------------------+------------+\n",
      "|Electronic access...|              4.76|      2587.5|\n",
      "| Fashion accessories|              4.76|      2586.0|\n",
      "|  Food and beverages|              4.76|     2673.56|\n",
      "|   Health and beauty|              4.76|     2342.56|\n",
      "|  Home and lifestyle|              4.76|     2564.85|\n",
      "|   Sports and travel|              4.76|      2624.9|\n",
      "+--------------------+------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_df(\"\"\"SELECT `Product line`, round(avg(`gross margin percentage`),2) as Avg_margin_percent, \n",
    "            round(sum(`Gross income`),2) as total_profit\n",
    "           FROM sales\n",
    "           GROUP BY `Product line`\n",
    "           ORDER BY `Product line` ASC\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+-----------+\n",
      "|        Product line|Gender|total_sales|\n",
      "+--------------------+------+-----------+\n",
      "|Electronic access...|Female|    27102.0|\n",
      "|Electronic access...|  Male|    27236.0|\n",
      "| Fashion accessories|Female|    30437.0|\n",
      "| Fashion accessories|  Male|    23868.0|\n",
      "|  Food and beverages|Female|    33171.0|\n",
      "|  Food and beverages|  Male|    22974.0|\n",
      "|   Health and beauty|Female|    18561.0|\n",
      "|   Health and beauty|  Male|    30633.0|\n",
      "|  Home and lifestyle|Female|    30037.0|\n",
      "|  Home and lifestyle|  Male|    23825.0|\n",
      "|   Sports and travel|Female|    28575.0|\n",
      "|   Sports and travel|  Male|    26548.0|\n",
      "+--------------------+------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sales by product line and gender\n",
    "show_df(\"\"\"SELECT `Product line`, Gender, round(sum(`Total`)) as total_sales\n",
    "           FROM sales\n",
    "           GROUP BY `Product line`, Gender\n",
    "           ORDER BY  `Product line` ASC, Gender ASC\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select by Branch\n",
    "What  branches are successfully satisfying customers and successfully generating profit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------+\n",
      "|Branch|branch_sales|\n",
      "+------+------------+\n",
      "|     A|         340|\n",
      "|     B|         332|\n",
      "|     C|         328|\n",
      "+------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_df(\"\"\"SELECT Branch, COUNT(*) as branch_sales\n",
    "                                            FROM Sales \n",
    "                                            GROUP by Branch\n",
    "                                            ORDER BY BRANCH\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+-----------------+\n",
      "|Branch|Avg_rating|     Total_profit|\n",
      "+------+----------+-----------------+\n",
      "|     A|     7.027|5057.160500000002|\n",
      "|     B|     6.818|5057.032000000003|\n",
      "|     C|     7.073|5265.176500000002|\n",
      "+------+----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output =  spark.sql(\"\"\"SELECT Branch, Round(avg(rating),3) as Avg_rating, sum(`gross income`) as Total_profit\n",
    "                        FROM sales\n",
    "                        GROUP BY Branch\n",
    "                        ORDER BY Branch ASC\"\"\")\n",
    "output.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Using Common Table Expression to get the Revenue by Branch for practice (even though there is no need to use it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+-----------------+------------------+\n",
      "|BRANCH|     Cost_of_goods|           profit|           Revenue|\n",
      "+------+------------------+-----------------+------------------+\n",
      "|     A|101143.21000000006|5057.160500000002|106200.37050000006|\n",
      "|     B|101140.63999999993|5057.032000000003|106197.67199999993|\n",
      "|     C|         105303.53|5265.176500000002|       110568.7065|\n",
      "+------+------------------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_df(\"\"\"WITH C as (SELECT Branch, sum(`Unit price` * Quantity) as Cogs\n",
    "                             FROM sales\n",
    "                             GROUP BY Branch),\n",
    "       P as (SELECT Branch, sum(`gross income`) as Profit\n",
    "                             FROM sales\n",
    "                             GROUP BY Branch)\n",
    "        SELECT C.BRANCH, C.Cogs as Cost_of_goods, P.profit, (C.cogs + P.Profit) as Revenue\n",
    "        FROM C \n",
    "        JOIN P ON C.Branch = P.Branch\n",
    "        ORDER BY C.BRANCH ASC\n",
    "        \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------------+\n",
      "|max(gross income)|min(gross income)|\n",
      "+-----------------+-----------------+\n",
      "|            49.65|           0.5085|\n",
      "+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_df(\"\"\"select max(`gross income`), min(`gross income`)\n",
    "            from sales\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+---------------+-----------------------+\n",
      "|Branch|        Product line|Number of sales|Percent of branch sales|\n",
      "+------+--------------------+---------------+-----------------------+\n",
      "|     A|Electronic access...|             60|                  0.176|\n",
      "|     A| Fashion accessories|             51|                   0.15|\n",
      "|     A|  Food and beverages|             58|                  0.171|\n",
      "|     A|   Health and beauty|             47|                  0.138|\n",
      "|     A|  Home and lifestyle|             65|                  0.191|\n",
      "|     A|   Sports and travel|             59|                  0.174|\n",
      "|     B|Electronic access...|             55|                  0.166|\n",
      "|     B| Fashion accessories|             62|                  0.187|\n",
      "|     B|  Food and beverages|             50|                  0.151|\n",
      "|     B|   Health and beauty|             53|                   0.16|\n",
      "|     B|  Home and lifestyle|             50|                  0.151|\n",
      "|     B|   Sports and travel|             62|                  0.187|\n",
      "|     C|Electronic access...|             55|                  0.168|\n",
      "|     C| Fashion accessories|             65|                  0.198|\n",
      "|     C|  Food and beverages|             66|                  0.201|\n",
      "|     C|   Health and beauty|             52|                  0.159|\n",
      "|     C|  Home and lifestyle|             45|                  0.137|\n",
      "|     C|   Sports and travel|             45|                  0.137|\n",
      "+------+--------------------+---------------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Is there a preference for certain product lines at certain branches?\n",
    "\n",
    "show_df(\"\"\"With BS as (SELECT Branch, COUNT(Distinct(`Invoice ID`)) as branch_sales\n",
    "                        FROM Sales \n",
    "                        GROUP by Branch  \n",
    "                            ),\n",
    "\n",
    "           PBS as (SELECT Branch, `Product line` as pl, Count(Distinct(`Invoice ID`)) as num_sales\n",
    "                    FROM sales\n",
    "                    GROUP BY Branch, `Product line`\n",
    "                    ORDER BY Branch ASC, `Product line`)\n",
    "                    \n",
    "            SELECT PBS.Branch, PBS.pl as `Product line`, PBS.num_sales as `Number of sales`, \n",
    "            Round(PBS.num_sales/BS.branch_sales, 3) as `Percent of branch sales`\n",
    "            FROM PBS join BS\n",
    "            ON PBS.Branch = Bs.Branch\n",
    "            ORDER BY Branch, `Product line`\n",
    "                        \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select by date\n",
    "What months and days of the week generate the most and least sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+\n",
      "|      Date| Invoice ID|\n",
      "+----------+-----------+\n",
      "|2019-01-01|765-26-6951|\n",
      "|2019-01-01|530-90-9855|\n",
      "|2019-01-01|891-01-7034|\n",
      "|2019-01-01|493-65-6248|\n",
      "|2019-01-01|556-97-7101|\n",
      "|2019-01-01|133-14-7229|\n",
      "|2019-01-01|651-88-7328|\n",
      "|2019-01-01|182-52-7000|\n",
      "|2019-01-01|416-17-9926|\n",
      "|2019-01-01|271-77-8740|\n",
      "|2019-01-01|770-42-8960|\n",
      "|2019-01-01|746-04-1077|\n",
      "|2019-01-02|504-35-8843|\n",
      "|2019-01-02|446-47-6729|\n",
      "|2019-01-02|244-08-0162|\n",
      "|2019-01-02|198-84-7132|\n",
      "|2019-01-02|744-09-5786|\n",
      "|2019-01-02|712-39-0363|\n",
      "|2019-01-02|345-68-9016|\n",
      "|2019-01-02|670-71-7306|\n",
      "+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Invoices in the first 2 days\n",
    "show_df(\"\"\"SELECT Date, `Invoice ID`\n",
    "            FROM sales\n",
    "            WHERE DATE_TRUNC('day', Date) = '2019-01-01' or DATE_TRUNC('day', Date) = '2019-01-02'\n",
    "            SORT BY Date\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+------------+\n",
      "|Branch|              Month|Gross_income|\n",
      "+------+-------------------+------------+\n",
      "|     A|2019-01-01 00:00:00|     1841.96|\n",
      "|     A|2019-02-01 00:00:00|     1421.91|\n",
      "|     A|2019-03-01 00:00:00|     1793.29|\n",
      "|     B|2019-01-01 00:00:00|     1770.29|\n",
      "|     B|2019-02-01 00:00:00|     1639.25|\n",
      "|     B|2019-03-01 00:00:00|     1647.49|\n",
      "|     C|2019-01-01 00:00:00|     1925.46|\n",
      "|     C|2019-02-01 00:00:00|     1568.33|\n",
      "|     C|2019-03-01 00:00:00|     1771.38|\n",
      "+------+-------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Monthly income by branch per month\n",
    "show_df(\"\"\"SELECT Branch, DATE_TRUNC('month', Date) as Month, Round(Sum(`Gross income`),2) as Gross_income \n",
    "            FROM sales\n",
    "            GROUP BY Branch, Month\n",
    "            ORDER BY Branch, Month\n",
    "            \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+------------+\n",
      "|Branch|              Month|Gross_income|\n",
      "+------+-------------------+------------+\n",
      "|     A|2019-01-01 00:00:00|     1841.96|\n",
      "|     A|2019-02-01 00:00:00|     1421.91|\n",
      "|     B|2019-01-01 00:00:00|     1770.29|\n",
      "|     B|2019-02-01 00:00:00|     1639.25|\n",
      "|     C|2019-01-01 00:00:00|     1925.46|\n",
      "|     C|2019-02-01 00:00:00|     1568.33|\n",
      "+------+-------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Monthly income by branch for first 2 months\n",
    "show_df(\"\"\"SELECT Branch, DATE_TRUNC('month', Date) as Month, Round(Sum(`Gross income`),2) as Gross_income \n",
    "            FROM sales\n",
    "            WHERE DATE_TRUNC('Month', Date) = '2019-01-01' or DATE_TRUNC('Month', Date) = '2019-02-01'\n",
    "            GROUP BY Branch, Month\n",
    "            ORDER BY Branch, Month\n",
    "            \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+-----------------------------+\n",
      "|Day_of_week|Transactions|Average_sales_per_transaction|\n",
      "+-----------+------------+-----------------------------+\n",
      "|          1|         133|                     334.2699|\n",
      "|          2|         125|                     303.1926|\n",
      "|          3|         158|                      325.837|\n",
      "|          4|         143|                     305.8121|\n",
      "|          5|         138|                     328.6177|\n",
      "|          6|         139|                     316.0168|\n",
      "|          7|         164|                     342.2001|\n",
      "+-----------+------------+-----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# What days of the week have the most and least sales\n",
    "# Sunday is 1, Saturday is 7\n",
    "show_df(\"\"\"SELECT dayofweek(Date) as Day_of_week, count(*) as Transactions, Round(AVG(Total),4) as Average_sales_per_transaction\n",
    "            FROM sales\n",
    "            GROUP BY Day_of_week\n",
    "            ORDER BY Day_of_week\n",
    "            Limit 7\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sales analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "|      sales_category|Frequency|\n",
      "+--------------------+---------+\n",
      "|     Low-price sales|       12|\n",
      "|Moderate-price sales|      196|\n",
      "|     Mid-price sales|      361|\n",
      "|    High-price sales|      431|\n",
      "+--------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_df(\"\"\"SELECT CASE\n",
    "            WHEN total < 20 THEN 'Low-price sales'\n",
    "            WHEN total < 100 THEN 'Moderate-price sales'\n",
    "            WHEN total < 300 THEN 'Mid-price sales'\n",
    "            ELSE 'High-price sales'\n",
    "            END AS sales_category, COUNT(*) as Frequency\n",
    "            FROM SALES\n",
    "            GROUP BY sales_category\n",
    "            ORDER BY Frequency\n",
    "            \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+---------+\n",
      "|Sales_rounded_down_100|Frequency|\n",
      "+----------------------+---------+\n",
      "|                     0|      208|\n",
      "|                   100|      202|\n",
      "|                   200|      159|\n",
      "|                   300|      111|\n",
      "|                   400|       93|\n",
      "|                   500|       67|\n",
      "|                   600|       51|\n",
      "|                   700|       51|\n",
      "|                   800|       32|\n",
      "|                   900|       17|\n",
      "|                  1000|        9|\n",
      "+----------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_df('''SELECT floor(total/100)*100 as Sales_rounded_down_100, count(*) as Frequency \n",
    "        FROM sales\n",
    "        GROUP by Sales_rounded_down_100 \n",
    "        order by Sales_rounded_down_100''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing sales Sales by weeks\n",
    "### Running total sales, Lagged sales, Sales delta/growth by week\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+\n",
      "|         Week_start|Sales|\n",
      "+-------------------+-----+\n",
      "|2018-12-31 00:00:00|   55|\n",
      "|2019-01-07 00:00:00|   73|\n",
      "|2019-01-14 00:00:00|   82|\n",
      "|2019-01-21 00:00:00|   93|\n",
      "|2019-01-28 00:00:00|   83|\n",
      "|2019-02-04 00:00:00|   92|\n",
      "|2019-02-11 00:00:00|   72|\n",
      "|2019-02-18 00:00:00|   60|\n",
      "|2019-02-25 00:00:00|   87|\n",
      "|2019-03-04 00:00:00|   88|\n",
      "|2019-03-11 00:00:00|   78|\n",
      "|2019-03-18 00:00:00|   76|\n",
      "|2019-03-25 00:00:00|   61|\n",
      "+-------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Weekly sales count\n",
    "show_df(\"\"\"SELECT DATE_TRUNC('week', Date) as Week_start, COUNT(*) as Sales\n",
    "            FROM sales\n",
    "            GROUP BY Week_start\n",
    "            ORDER BY Week_start ASC\n",
    "            \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+-------------+\n",
      "|         Week_start|sales|Running_sales|\n",
      "+-------------------+-----+-------------+\n",
      "|2018-12-31 00:00:00|   55|           55|\n",
      "|2019-01-07 00:00:00|   73|          128|\n",
      "|2019-01-14 00:00:00|   82|          210|\n",
      "|2019-01-21 00:00:00|   93|          303|\n",
      "|2019-01-28 00:00:00|   83|          386|\n",
      "|2019-02-04 00:00:00|   92|          478|\n",
      "|2019-02-11 00:00:00|   72|          550|\n",
      "|2019-02-18 00:00:00|   60|          610|\n",
      "|2019-02-25 00:00:00|   87|          697|\n",
      "|2019-03-04 00:00:00|   88|          785|\n",
      "|2019-03-11 00:00:00|   78|          863|\n",
      "|2019-03-18 00:00:00|   76|          939|\n",
      "|2019-03-25 00:00:00|   61|         1000|\n",
      "+-------------------+-----+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Weekly running sales\n",
    "show_df(\"\"\"WITH weekly_sales as(SELECT DATE_TRUNC('week', Date) as Week_start, COUNT(*) as sales\n",
    "            FROM sales\n",
    "            GROUP BY Week_start\n",
    "            ORDER BY Week_start ASC)\n",
    "            \n",
    "            SELECT Week_start, sales, sum(sales) over (ORDER BY Week_start ASC) as Running_sales\n",
    "            FROM weekly_sales\n",
    "            ORDER BY Week_start ASC\n",
    "            \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+------------+\n",
      "|         Week_start|sales|Lagged_sales|\n",
      "+-------------------+-----+------------+\n",
      "|2018-12-31 00:00:00|   55|           0|\n",
      "|2019-01-07 00:00:00|   73|          55|\n",
      "|2019-01-14 00:00:00|   82|          73|\n",
      "|2019-01-21 00:00:00|   93|          82|\n",
      "|2019-01-28 00:00:00|   83|          93|\n",
      "|2019-02-04 00:00:00|   92|          83|\n",
      "|2019-02-11 00:00:00|   72|          92|\n",
      "|2019-02-18 00:00:00|   60|          72|\n",
      "|2019-02-25 00:00:00|   87|          60|\n",
      "|2019-03-04 00:00:00|   88|          87|\n",
      "|2019-03-11 00:00:00|   78|          88|\n",
      "|2019-03-18 00:00:00|   76|          78|\n",
      "|2019-03-25 00:00:00|   61|          76|\n",
      "+-------------------+-----+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Weekly Lagged sales\n",
    "show_df(\"\"\"WITH weekly_sales as(SELECT DATE_TRUNC('week', Date) as Week_start, COUNT(*) as sales\n",
    "            FROM sales\n",
    "            GROUP BY Week_start\n",
    "            ORDER BY Week_start ASC)\n",
    "            \n",
    "            SELECT Week_start, sales, coalesce(lag(sales) over (ORDER BY Week_start ASC), 0) as Lagged_sales\n",
    "            FROM weekly_sales\n",
    "            ORDER BY Week_start ASC\n",
    "            \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------+------------+\n",
      "|         Week_start|Sales_delta|Sales_growth|\n",
      "+-------------------+-----------+------------+\n",
      "|2018-12-31 00:00:00|          5|         0.1|\n",
      "|2019-01-07 00:00:00|         18|        0.33|\n",
      "|2019-01-14 00:00:00|          9|        0.12|\n",
      "|2019-01-21 00:00:00|         11|        0.13|\n",
      "|2019-01-28 00:00:00|        -10|       -0.11|\n",
      "|2019-02-04 00:00:00|          9|        0.11|\n",
      "|2019-02-11 00:00:00|        -20|       -0.22|\n",
      "|2019-02-18 00:00:00|        -12|       -0.17|\n",
      "|2019-02-25 00:00:00|         27|        0.45|\n",
      "|2019-03-04 00:00:00|          1|        0.01|\n",
      "|2019-03-11 00:00:00|        -10|       -0.11|\n",
      "|2019-03-18 00:00:00|         -2|       -0.03|\n",
      "|2019-03-25 00:00:00|        -15|        -0.2|\n",
      "+-------------------+-----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Changes in number of sales every week and changes in sales growth (Percent)\n",
    "# ASSUME THAT THERE WERE 50 SALES IN THE WEEK PRIOR TO THE WEEK THAT BEGAN ON 2019-12-31\n",
    "\n",
    "show_df(\"\"\"WITH weekly_sales as(SELECT DATE_TRUNC('week', Date) as Week_start, COUNT(*) as Sales\n",
    "            FROM sales\n",
    "            GROUP BY Week_start\n",
    "            ORDER BY Week_start ASC),\n",
    "            \n",
    "            weekly_sales_lag as(SELECT Week_start, sales, coalesce(lag(sales) over (ORDER BY Week_start ASC), 50) as Lagged_sales\n",
    "            FROM weekly_sales\n",
    "            ORDER BY Week_start ASC)\n",
    "            \n",
    "            SELECT Week_start, Sales-Lagged_sales as Sales_delta, round((Sales-Lagged_sales)/Lagged_sales,2) as Sales_growth\n",
    "            FROM weekly_sales_lag\n",
    "            ORDER BY Week_start ASC\n",
    "            \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------+--------------+\n",
      "|         Week_start|Revenue_delta|Revenue_growth|\n",
      "+-------------------+-------------+--------------+\n",
      "|2018-12-31 00:00:00|      7543.39|          0.75|\n",
      "|2019-01-07 00:00:00|      6917.81|          0.39|\n",
      "|2019-01-14 00:00:00|      4232.16|          0.17|\n",
      "|2019-01-21 00:00:00|       593.52|          0.02|\n",
      "|2019-01-28 00:00:00|      -926.44|         -0.03|\n",
      "|2019-02-04 00:00:00|     -1258.61|         -0.04|\n",
      "|2019-02-11 00:00:00|     -1538.24|         -0.06|\n",
      "|2019-02-18 00:00:00|     -8234.93|         -0.32|\n",
      "|2019-02-25 00:00:00|     11891.05|          0.69|\n",
      "|2019-03-04 00:00:00|      -800.88|         -0.03|\n",
      "|2019-03-11 00:00:00|     -4428.62|         -0.16|\n",
      "|2019-03-18 00:00:00|      1130.38|          0.05|\n",
      "|2019-03-25 00:00:00|      -7242.6|         -0.29|\n",
      "+-------------------+-------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Changes in number of sales every week and changes in sales growth (Percent)\n",
    "# Assume Income in prior week was 10000\n",
    "\n",
    "show_df(\"\"\"WITH weekly_sales as(SELECT DATE_TRUNC('week', Date) as Week_start, SUM(Total) as Sales\n",
    "            FROM sales\n",
    "            GROUP BY Week_start\n",
    "            ORDER BY Week_start ASC),\n",
    "            -- Assume income in prior week\n",
    "            weekly_sales_lag as(SELECT Week_start, Sales, coalesce(lag(Sales) over (ORDER BY Week_start ASC), 10000) as Lagged_sales\n",
    "            FROM weekly_sales\n",
    "            ORDER BY Week_start ASC)\n",
    "            \n",
    "            SELECT Week_start, Round(Sales-Lagged_sales,2) as Revenue_delta, round((Sales-Lagged_sales)/Lagged_sales,2) as Revenue_growth\n",
    "            FROM weekly_sales_lag\n",
    "            ORDER BY Week_start ASC\n",
    "            \"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
